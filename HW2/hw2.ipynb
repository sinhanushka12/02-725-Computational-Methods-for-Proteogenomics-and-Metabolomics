{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file\n",
    "def read_file(txt_file):\n",
    "    lines = []\n",
    "    with open(txt_file, \"r\") as file:\n",
    "        l = file.readlines()\n",
    "        for i in l:\n",
    "            lines.append(i.strip())\n",
    "    return lines\n",
    "\n",
    "encoding_txt_file = read_file(\"encoding_regions.txt\")\n",
    "non_encoding_txt_file = read_file(\"non_encoding_regions.txt\")\n",
    "unlabelled_txt_file = read_file(\"unlabelled.txt\")\n",
    "genome_txt_file = read_file(\"genome.txt\")\n",
    "len(genome_txt_file[0])\n",
    "# genome_txt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission probabiliites in the encoding txt file {'G': 0.3999818, 'C': 0.3999538, 'T': 0.1000112, 'A': 0.1000532}\n",
      "Emission probabiliites in the non encoding txt file {'C': 0.2501792, 'G': 0.249929, 'T': 0.2499335, 'A': 0.2499583}\n"
     ]
    }
   ],
   "source": [
    "def freq_of_nucleotides(region_data):\n",
    "    frequency = dict()\n",
    "    for line in range(len(region_data)):\n",
    "        for char in region_data[line]:\n",
    "            if char not in frequency:\n",
    "                frequency[char] = 1 \n",
    "            else:\n",
    "                frequency[char] += 1 \n",
    "    return frequency\n",
    "\n",
    "\n",
    "def get_emission_probs(freq_dict):\n",
    "    emission_probabilities = dict()\n",
    "    count_probabilities = sum(freq_dict.values())\n",
    "    for key in freq_dict:\n",
    "        emission_probabilities[key] = freq_dict[key]/count_probabilities\n",
    "    return emission_probabilities\n",
    "\n",
    "a = freq_of_nucleotides(encoding_txt_file)    \n",
    "b = freq_of_nucleotides(non_encoding_txt_file) \n",
    "emi_encoding = get_emission_probs(a)\n",
    "emi_noncoding = get_emission_probs(b)\n",
    "print(\"Emission probabiliites in the encoding txt file\", emi_encoding)\n",
    "print(\"Emission probabiliites in the non encoding txt file\", emi_noncoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gene-finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_finding(encoding_emi_probs, non_encoding_emi_probs, txt_file):\n",
    "    gene_find_txt = open(\"HW2 2.txt\", \"a\")\n",
    "    # 0 = non encoding, 1 = encoding\n",
    "    for gene in txt_file:\n",
    "        prob_encoding = 0\n",
    "        prob_non_encoding = 0 \n",
    "        for char in gene:\n",
    "            prob_encoding += math.log(encoding_emi_probs[char])\n",
    "            prob_non_encoding += math.log(non_encoding_emi_probs[char])\n",
    "        if prob_encoding > prob_non_encoding:\n",
    "            gene_find_txt.write(\"1\\n\")\n",
    "        else:\n",
    "            gene_find_txt.write(\"0\\n\")\n",
    "    gene_find_txt.close()\n",
    "\n",
    "# gene_finding(emi_encoding, emi_noncoding, unlabelled_txt_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(txt_file, transition_matrix, emission_matrix, start_dict, states):\n",
    "    \n",
    "    viterbi_matrix = np.zeros((len(txt_file[0]),2)) # 100000 x 2\n",
    "    \n",
    "    for char_index in range(len(txt_file[0])):\n",
    "        for state in range(len(states)):\n",
    "            if char_index == 0:\n",
    "                viterbi_matrix[char_index, state] = math.log(start_dict[state]) + math.log(emission_matrix[state][txt_file[0][char_index]])\n",
    "            else:\n",
    "                first_term = viterbi_matrix[char_index-1, 0] + math.log(transition_matrix[0][state])\n",
    "                second_term = viterbi_matrix[char_index-1, 1] + math.log(transition_matrix[1][state])\n",
    "                max_probability = max(first_term, second_term)\n",
    "                viterbi_matrix[char_index, state] = max_probability + math.log(emission_matrix[state][txt_file[0][char_index]])\n",
    "\n",
    "    trace_path_matrix = np.zeros((len(txt_file[0])), dtype=int)\n",
    "    trace_path_matrix[-1] = np.argmax([viterbi_matrix[-1]])\n",
    "    for i in range(len(viterbi_matrix)-2, -1,-1): \n",
    "        trace_path_matrix[i] = np.argmax([viterbi_matrix[i, 0]+ math.log(transition_matrix[0][trace_path_matrix[i+1]]), viterbi_matrix[i,1] + math.log(transition_matrix[1][trace_path_matrix[i+1]])])\n",
    "    \n",
    "    return trace_path_matrix\n",
    "    \n",
    "\n",
    "\n",
    "# 1 - encoding region, 0 - non-encoding region\n",
    "states = ['1', '0']\n",
    "\n",
    "observations = ('A', 'C', 'G', 'T')\n",
    "\n",
    "start_probability = {1: 0.5, 0: 0.5}\n",
    "\n",
    "transition_probability = [[0.999, 0.001],[0.001, 0.999]]\n",
    "\n",
    "emission_probability = {\n",
    "1 : {'A': 0.1000532, 'C': 0.3999538, 'G': 0.3999818, 'T': 0.1000112},\n",
    "0 : {'A': 0.2499583, 'C': 0.2501792, 'G': 0.249929, 'T': 0.2499335},\n",
    "}\n",
    "\n",
    "trace_path_array = viterbi_decoding(genome_txt_file, transition_probability, emission_probability, start_probability, states)\n",
    "np.savetxt('HW2_3.txt', trace_path_array, fmt='%d', delimiter='', newline='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_indices(trace_path): \n",
    "    num = trace_path\n",
    "    changes = [[int(num[0]), 0]]\n",
    "    for i in range(1, len(num)):\n",
    "        if num[i] != num[i-1]:\n",
    "            changes[-1].append(i-1)\n",
    "            changes.append([int(num[i]), i])\n",
    "    changes[-1].append(len(num)-1)\n",
    "\n",
    "    indices = {1:[],0:[]}\n",
    "    for change in changes:\n",
    "        indices[change[0]].append((change[1], change[-1]))\n",
    "    return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_frequencies(txt_file_non_encoded, indices):\n",
    "    encoding_frequencies = dict()\n",
    "    non_encoding_frequencies = dict()\n",
    "    for i in indices: \n",
    "        for tup in indices[i]:\n",
    "            start_index = tup[0]\n",
    "            end_index = tup[-1]\n",
    "            for char in txt_file_non_encoded[0][start_index:end_index+1]:\n",
    "                if i == 1:\n",
    "                    if char not in encoding_frequencies:\n",
    "                        encoding_frequencies[char] = 1 \n",
    "                    else:\n",
    "                        encoding_frequencies[char] += 1\n",
    "                elif i == 0:\n",
    "                    if char not in non_encoding_frequencies:\n",
    "                        non_encoding_frequencies[char] = 1 \n",
    "                    else:\n",
    "                        non_encoding_frequencies[char] += 1\n",
    "    return encoding_frequencies, non_encoding_frequencies\n",
    "    \n",
    "def update_transition_matrix(trace_path_matrix):\n",
    "    new_mat = [[0,0],[0,0]]\n",
    "    for i in range(len(trace_path_matrix)-1):\n",
    "        new_mat[trace_path_matrix[i]][trace_path_matrix[i+1]] += 1\n",
    "    denom = [sum(new_mat[0]), sum(new_mat[1])]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            new_mat[i][j] *= 1/denom[i]\n",
    "    return new_mat    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number 0\n",
      "Transition Matrix\n",
      " [[9.99859006e-01 1.40993715e-04]\n",
      " [3.86819889e-03 9.96131801e-01]]\n",
      "Emission Matrix \n",
      "  {1: {'A': 0.11373069429934778, 'C': 0.38413756105824887, 'G': 0.3878363497755315, 'T': 0.11429539486687185}, 0: {'A': 0.22934366456800503, 'C': 0.27038212367416803, 'G': 0.2706827717262278, 'T': 0.22959144003159915}}\n",
      "\n",
      "\n",
      "Iteration Number 1\n",
      "Transition Matrix\n",
      " [[9.99893635e-01 1.06364742e-04]\n",
      " [3.28770588e-03 9.96712294e-01]]\n",
      "Emission Matrix \n",
      "  {1: {'A': 0.11269876394904056, 'C': 0.38361837321784215, 'G': 0.3891189580501375, 'T': 0.1145639047829798}, 0: {'A': 0.22892560361928896, 'C': 0.27084359545502895, 'G': 0.2710986640395635, 'T': 0.22913213688611858}}\n",
      "\n",
      "\n",
      "Iteration Number 2\n",
      "Transition Matrix\n",
      " [[9.99894686e-01 1.05314130e-04]\n",
      " [3.27316639e-03 9.96726834e-01]]\n",
      "Emission Matrix \n",
      "  {1: {'A': 0.11224100673700267, 'C': 0.3839455955256133, 'G': 0.38890301258421256, 'T': 0.11491038515317148}, 0: {'A': 0.22892067582692158, 'C': 0.27085217628328234, 'G': 0.27112578624144584, 'T': 0.2291013616483503}}\n",
      "\n",
      "\n",
      "Iteration Number 3\n",
      "Transition Matrix\n",
      " [[9.99894692e-01 1.05308259e-04]\n",
      " [3.27879289e-03 9.96721207e-01]]\n",
      "Emission Matrix \n",
      "  {1: {'A': 0.11198828547781244, 'C': 0.38435092633857515, 'G': 0.3886802062774559, 'T': 0.1149805819061565}, 0: {'A': 0.22892236724462256, 'C': 0.2708453353651612, 'G': 0.2711395787261018, 'T': 0.2290927186641145}}\n",
      "\n",
      "\n",
      "Iteration Number 4\n",
      "Transition Matrix\n",
      " [[9.99894691e-01 1.05309237e-04]\n",
      " [3.27785380e-03 9.96722146e-01]]\n",
      "Emission Matrix \n",
      "  {1: {'A': 0.11195621041911975, 'C': 0.38443178563472613, 'G': 0.38856888266556344, 'T': 0.11504312128059065}, 0: {'A': 0.22892449438712667, 'C': 0.27084165740049576, 'G': 0.27114209815017287, 'T': 0.22909175006220467}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def learning_hmm(txt_file, start_dict, states, trace_path): \n",
    "    for i in range(5):\n",
    "        # Get indices \n",
    "        indices = get_state_indices(trace_path)\n",
    "        \n",
    "        # Update transition matrix\n",
    "        transition_matrix = update_transition_matrix(trace_path)\n",
    "        \n",
    "        # Update emission probabilities \n",
    "        en_freq, non_en_freq = update_frequencies(txt_file, indices)\n",
    "        em_mat_encoding = get_emission_probs(en_freq)\n",
    "        em_mat_non_encoding = get_emission_probs(non_en_freq)\n",
    "        emission_matrix = {\n",
    "                    1 : {'A': em_mat_encoding['A'], 'C': em_mat_encoding['C'], 'G': em_mat_encoding['G'], 'T': em_mat_encoding['T']},\n",
    "                    0 : {'A': em_mat_non_encoding['A'], 'C': em_mat_non_encoding['C'], 'G': em_mat_non_encoding['G'], 'T': em_mat_non_encoding['T']},\n",
    "                    }\n",
    "        print(f\"Iteration Number {i}\")\n",
    "        print(\"Transition Matrix\\n\", np.array(transition_matrix))\n",
    "        print(\"Emission Matrix \\n \" ,emission_matrix)\n",
    "        print(\"\\n\")\n",
    "        # Viterbi Decoding  \n",
    "        trace_path = viterbi_decoding(txt_file, transition_matrix, emission_matrix, start_dict, states)\n",
    "\n",
    "learning_hmm(genome_txt_file, start_probability, states, trace_path_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. HMM Duration Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda for encoding regions 0.0038832199546485263\n",
      "Lambda for non encoding regions 0.00014205046213059102\n"
     ]
    }
   ],
   "source": [
    "def get_duration_distributions(regions):\n",
    "    encoding_num_observerations = 0\n",
    "    non_encoding_num_observations = 0\n",
    "    for i in regions: \n",
    "        if i == 1:\n",
    "            encoding_num_regions = len(regions[i])\n",
    "            for tup in regions[i]:\n",
    "                encoding_num_observerations += tup[-1] - tup[0]\n",
    "            lambda_encoding = encoding_num_regions/encoding_num_observerations\n",
    "        elif i == 0:\n",
    "            non_encoding_num_regions = len(regions[i])\n",
    "            for tup in regions[i]:\n",
    "                non_encoding_num_observations += tup[-1] - tup[0]\n",
    "            lambda_non_encoding = non_encoding_num_regions/non_encoding_num_observations\n",
    "    return lambda_encoding, lambda_non_encoding\n",
    "\n",
    "pairs = get_state_indices(trace_path_array)\n",
    "lamba_MLE_encoding, lamba_MLE_non_encoding = get_duration_distributions(pairs)\n",
    "print(\"Lambda for encoding regions\", lamba_MLE_encoding)\n",
    "print(\"Lambda for non encoding regions\", lamba_MLE_non_encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70d57c135da11913b2ad31fa6150ab201732e694e7c1a956b2909783da6a3273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
